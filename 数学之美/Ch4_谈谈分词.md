谈谈分词

1. 中文分词的演变
	- 查词典
	- 统计语言模型
2. 衡量分词的结果
    - 分词的一致性
    - 词的粒度和层次

# 1.中文分词的演变

## （1）查词典

最容易想到的分词方法，也是最简单的办法，就是查字典。这种简单的方法可以解决七八成以上的分词问题。但遇到稍微复杂一点的问题就无能为力了。


## （2）统计语言模型

统计语言模型成功解决了分词二义性问题，将汉语分词错误率降低了一个数量级。

**模型简介**

假定句子`S`可以有三种分词方法：

	A1, A2, A3, ..., Ak,
	B1, B2, B3, ..., Bm
	C1, C2, C3, ..., Cn

其中，`A1, A2, B1, B2, C1, C2` 等等都是汉语单词。最好的分词方法应保证分完词后句子出现的概率最大。即如果 `A1,A2,..., Ak`是最好的分法，那么：

	P(A1, A2, A3, ..., Ak) > P(B1, B2, B3, ..., Bm),
	并且
	P(A1, A2, A3, ..., Ak) > P(C1, C2, C3, ..., Cn)

因此，只要利用统计语言模型计算出每种分词后句子出现的概率，并找出其中概率最大的，就能够找到最好的分词方法。

如果我们穷举所有可能的分词方法并计算出每种可能性下句子的概率，那么计算量相当大。因此，我们可以把它看成是一个动态规划（Dynamic Programming) 的问题，并利用 “维特比”（Viterbi） 算法快速地找到最佳分词。


**注意两点**

- 应用不同，汉语分词的粒度大小应该不同
- 中文的分词方法也被应用与英文处理，主要是手写体识别中。因为在识别手写体时，单词间的空格不是
很清楚

# 2.衡量分词的结果

## （1）分词的一致性
不同的人对同一个句子可能有不同的分词方法。比如有的人认为`清华大学`应该是一个词，有的人却认为应该把`清华`和`大学`分开。

## （2）词的粒度和层次
人工分词产生不一致的原因主要在于人们对词的颗粒度的认识不同。在不同的应用场景中，会有一种
颗粒度比另一种更好的情况。比如在机器翻译中，一般来讲，颗粒度大翻译效果好。

我们可以构造不同（粒度）的分词器，但是这样做不仅浪费，而且没有必要。更好的做法是**让一个分词器同时支持不同层次的词的切分**。

